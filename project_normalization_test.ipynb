{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ecad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9b2f8",
   "metadata": {},
   "source": [
    "# Setup Up GPU (Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ec1873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483acaa2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b6c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(\"data/train.csv\")\n",
    "df_te = pd.read_csv('data/test_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e64d6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1372636858620000589         C          NaN           NaN  20000589   \n",
       "1  1372637303620000596         B          NaN           7.0  20000596   \n",
       "2  1372636951620000320         C          NaN           NaN  20000320   \n",
       "3  1372636854620000520         C          NaN           NaN  20000520   \n",
       "4  1372637091620000337         C          NaN           NaN  20000337   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  1372636858        A         False   \n",
       "1  1372637303        A         False   \n",
       "2  1372636951        A         False   \n",
       "3  1372636854        A         False   \n",
       "4  1372637091        A         False   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643,41.141412],[-8.618499,41.141376],[...  \n",
       "1  [[-8.639847,41.159826],[-8.640351,41.159871],[...  \n",
       "2  [[-8.612964,41.140359],[-8.613378,41.14035],[-...  \n",
       "3  [[-8.574678,41.151951],[-8.574705,41.151942],[...  \n",
       "4  [[-8.645994,41.18049],[-8.645949,41.180517],[-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779aa61",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda2ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over every single \n",
    "# This code creates a new column, \"LEN\", in our dataframe. The value is\n",
    "# the (polyline_length - 1) * 15, where polyline_length = count(\"[\") - 1\n",
    "def polyline_to_trip_duration(polyline):\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "# Each x is essentially a 1 row, 1 column pandas Series\n",
    "def parse_time(x):\n",
    "    dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "    return dt.year, dt.month, dt.day, dt.hour, dt.weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8f710",
   "metadata": {},
   "source": [
    "# Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c13d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process new features\n",
    "df_tr[\"LEN\"] = df_tr[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "\n",
    "df_tr[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_tr[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "df_te[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_te[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f105af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ohe(df, feat):\n",
    "    df = df.copy()\n",
    "    unique_vals = df_tr[feat].unique()\n",
    "    for val in unique_vals:\n",
    "        df[feat + '_' + str(val)] = df[feat].apply(lambda x: 1 if x==val else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ebc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop samples with missing data (count=10)\n",
    "df_tr = df_tr[df_tr['MISSING_DATA'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a615811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop samples with len < len_thresh\n",
    "len_thresh = 2000\n",
    "df_tr = df_tr[df_tr['LEN'] < len_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd3f4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_not_in_testing(df, feat):\n",
    "    temp = (df_tr[feat].value_counts(normalize=True).sort_index() - df_te[feat].value_counts(normalize=True).sort_index())\n",
    "    vals_to_remove = temp[temp.isna()].index\n",
    "    df = df[df[feat].apply(lambda x: x not in vals_to_remove)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a33e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['CALL_TYPE', 'HR', 'WK']\n",
    "# for feat in features_to_use:\n",
    "#     df_tr = drop_not_in_testing(df_tr, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db896b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful input features\n",
    "# features_to_use = ['CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C', 'MON', 'DAY', 'HR', 'WK']\n",
    "\n",
    "X = df_tr[features_to_use]\n",
    "for feat in ['CALL_TYPE']:\n",
    "    X = compute_ohe(X, feat)\n",
    "for feat in features_to_use[1:]:\n",
    "    X[feat] = (X[feat] - X[feat].mean())/X[feat].std()\n",
    "X = X.drop(columns=['CALL_TYPE'])\n",
    "y = df_tr['LEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7851f9",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06552a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into train,validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5f079",
   "metadata": {},
   "source": [
    "# Sklearn Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60c4ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9052c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.22392367369156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "359.40209865543534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(X_train, y_train)\n",
    "print(MSE(reg.predict(X_train), y_train, squared=False))\n",
    "MSE(reg.predict(X_test), y_test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8255bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353.34500473892956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "354.6697608961591"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "print(MSE(forest.predict(X_train), y_train, squared=False))\n",
    "MSE(forest.predict(X_test), y_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98143a1d",
   "metadata": {},
   "source": [
    "# Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4999e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_train = torch.from_numpy(X_train.values).to(torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train)).to(torch.float32).reshape(-1,1)\n",
    "X_test = torch.from_numpy(X_test.values).to(torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test)).to(torch.float32).reshape(-1,1)\n",
    "\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "data_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 2**8\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210443a",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7386852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        eps = 1e-6\n",
    "        loss = torch.sqrt(criterion(x, y) + eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727e22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(32,16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "\n",
    "        self.layerx = nn.Sequential(\n",
    "            nn.Linear(16,16),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(16,8),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(8,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)      \n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        x = self.layerx(x)\n",
    "        \n",
    "        x = self.layer4(x)      \n",
    "        x = self.layer5(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4408843",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a561cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# training_losses = []\n",
    "# criterion = nn.MSELoss()\n",
    "# net = model()\n",
    "# net.to(device)\n",
    "# # optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# TOTAL_EPOCHS = 10\n",
    "\n",
    "# for epoch in tqdm(range(1, TOTAL_EPOCHS + 1, 1)):\n",
    "#     running_loss = 0\n",
    "#     n = 0\n",
    "#     for x,y in train_loader:\n",
    "#         x,y = x.to(device), y.to(device)\n",
    "#         y_pred = net(x)\n",
    "#         loss  = criterion(y_pred, y)\n",
    "#         running_loss += loss.item()\n",
    "#         n += 1\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "        \n",
    "#     curr_loss = running_loss / n\n",
    "#     training_losses.append((epoch, curr_loss))\n",
    "#     print('epoch {}, loss {}'.format(epoch, curr_loss))\n",
    "    \n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c5c5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:59, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 380.47640016747187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:39<02:36, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 358.35649129714125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:57<02:12, 18.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 358.3447498833543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [01:16<01:53, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 358.3582281094833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [01:34<01:34, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 358.35039215088784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:53<01:14, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss 358.35054842153977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [02:12<00:56, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss 358.34894789250905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [02:32<00:38, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss 358.35843298655266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [02:51<00:19, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss 358.3405677415303\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "training_losses = []\n",
    "criterion = nn.MSELoss()\n",
    "net = model()\n",
    "net.to(device)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "TOTAL_EPOCHS = 10\n",
    "\n",
    "for epoch in tqdm(range(1, TOTAL_EPOCHS + 1, 1)):\n",
    "    running_loss = 0\n",
    "    n = 0 #len(data_train)\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        y_pred = net(x)\n",
    "        loss  = criterion(y_pred, y)\n",
    "        running_loss += loss.item()*len(x)\n",
    "        n += len(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    curr_loss = np.sqrt(running_loss / n)\n",
    "    training_losses.append((epoch, curr_loss))\n",
    "    print('epoch {}, loss {}'.format(epoch, curr_loss))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbf6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x[0] for x in training_losses], [x[1] for x in training_losses])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f1f43",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed451870",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(X_train.to(device)).detach().cpu().numpy()\n",
    "MSE(preds, y_train.cpu(), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(X_test.to(device)).detach().cpu().numpy()\n",
    "MSE(preds, y_test.cpu(), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(np.full(preds.shape, y_train.mean()), y_test.cpu(), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3e06c",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be085c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "df_te = df_te[df_te['MISSING_DATA']==False]\n",
    "\n",
    "# drop inputs not in test set\n",
    "# X_out = df_te[features_to_use]\n",
    "# for feat in features_to_use:\n",
    "#     X_out = drop_not_in_testing(X_out, feat)\n",
    "# ohe\n",
    "for feat in ['CALL_TYPE']:\n",
    "    X_out = compute_ohe(X_out, feat)\n",
    "# standardize\n",
    "for feat in features_to_use[1:]:\n",
    "    X_out[feat] = (X_out[feat] - X_out[feat].mean())/X_out[feat].std()\n",
    "X_out = X_out.drop(columns=['CALL_TYPE'])\n",
    "\n",
    "X_out = torch.from_numpy(X_out.values).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2716f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out = net(X_out.to(device)).detach().cpu().numpy()\n",
    "df_out = pd.DataFrame(data = {'TRIP_ID': np.array(df_te['TRIP_ID']), 'TRAVEL_TIME': preds_out.flatten()})\n",
    "df_out.to_csv('my_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078d000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
